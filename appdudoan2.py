import streamlit as st
import cv2
import numpy as np
import joblib
from PIL import Image
from skimage.feature import hog
import os
from pathlib import Path # TH√äM TH∆Ø VI·ªÜN PATHLIB QUAN TR·ªåNG NH·∫§T

# 1. ƒê·ªäNH NGHƒ®A ƒê∆Ø·ªúNG D·∫™N G·ªêC AN TO√ÄN TR√äN SERVER
# Th∆∞ m·ª•c g·ªëc l√† th∆∞ m·ª•c ch·ª©a file appdudoan.py n√†y
BASE_DIR = Path(__file__).parent 

# =======================
# LOAD MODEL + SCALER
# =======================

# 1.1 T·∫£i file ch·ª©a c·∫£ Model v√† th√¥ng tin. T√™n file n√†y ph·∫£i c√≥ tr√™n GitHub.
MODEL_FILE_NAME = "emotion_model.pkl"
try:
    emotion_model = joblib.load(BASE_DIR / MODEL_FILE_NAME)
    model = emotion_model["model"]
except FileNotFoundError:
    st.error(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file {MODEL_FILE_NAME}. H√£y ki·ªÉm tra tr√™n GitHub!")
    st.stop()


# 1.2 KH·∫ÆC PH·ª§C L·ªñI SCALER!
# Thay v√¨ l·∫•y ƒë∆∞·ªùng d·∫´n t·ª´ emotion_model (c√≥ th·ªÉ l√† ƒë∆∞·ªùng d·∫´n c·ª•c b·ªô), 
# ch√∫ng ta s·∫Ω ki·ªÉm tra xem scaler c√≥ ph·∫£i l√† m·ªôt ƒë·ªëi t∆∞·ª£ng (object) kh√¥ng, 
# ho·∫∑c gi·∫£ ƒë·ªãnh n√≥ l√† 'scaler.pkl' n·∫±m c√πng th∆∞ m·ª•c (gi·∫£ ƒë·ªãnh ph·ªï bi·∫øn).

scaler = None
scaler_is_file = False

# Tr∆∞·ªùng h·ª£p 1: Scaler l√† m·ªôt object ƒë∆∞·ª£c nh√∫ng s·∫µn trong emotion_model (t·ªët nh·∫•t)
if "scaler" in emotion_model and emotion_model["scaler"] is not None:
    scaler = emotion_model["scaler"]
    
# Tr∆∞·ªùng h·ª£p 2: Scaler l√† m·ªôt file ri√™ng (ch√∫ng ta ph·∫£i d√πng ƒë∆∞·ªùng d·∫´n an to√†n)
else:
    SCALER_FILE_NAME = "scaler.pkl" # ƒê·∫£m b·∫£o file n√†y c√≥ tr√™n GitHub
    scaler_path = BASE_DIR / SCALER_FILE_NAME
    
    if scaler_path.exists():
        try:
            scaler = joblib.load(scaler_path)
            scaler_is_file = True
        except Exception as e:
            st.error(f"‚ùå L·ªói khi t·∫£i file {SCALER_FILE_NAME}: {e}")
            st.stop()

# Ki·ªÉm tra cu·ªëi c√πng
if scaler is None:
    # ƒêo·∫°n code n√†y ch·ªâ ch·∫°y n·∫øu c·∫£ 2 tr∆∞·ªùng h·ª£p tr√™n ƒë·ªÅu th·∫•t b·∫°i
    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y scaler! ƒê·∫£m b·∫£o scaler.pkl c√≥ tr√™n GitHub ho·∫∑c ƒë√£ ƒë∆∞·ª£c nh√∫ng v√†o emotion_model.pkl.")
    st.stop()

labels = emotion_model["labels"]

# =======================
# LOAD FACE DETECTOR (DNN)
# =======================
# 2. KH·∫ÆC PH·ª§C L·ªñI ƒê∆Ø·ªúNG D·∫™N TUY·ªÜT ƒê·ªêI!
# Thay th·∫ø ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi (E:\...) b·∫±ng ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi an to√†n.
# Gi·∫£ ƒë·ªãnh c√°c file n√†y n·∫±m c√πng th∆∞ m·ª•c g·ªëc BASE_DIR.

CONFIG_FILE_NAME = "deploy.prototxt"
MODEL_FILE_NAME_DNN = "res10_300x300_ssd_iter_140000.caffemodel"

CONFIG_FILE = BASE_DIR / CONFIG_FILE_NAME
MODEL_FILE = BASE_DIR / MODEL_FILE_NAME_DNN

if not CONFIG_FILE.exists():
    st.error(f"Kh√¥ng t√¨m th·∫•y file c·∫•u h√¨nh DNN: {CONFIG_FILE_NAME}")
    st.stop()
if not MODEL_FILE.exists():
    st.error(f"Kh√¥ng t√¨m th·∫•y file model DNN: {MODEL_FILE_NAME_DNN}")
    st.stop()

net = cv2.dnn.readNetFromCaffe(str(CONFIG_FILE), str(MODEL_FILE)) # D√πng str() ƒë·ªÉ chuy·ªÉn Path object sang string

# =======================
# STREAMLIT UI (GI·ªÆ NGUY√äN)
# =======================
st.title("üòÑ ·ª®ng d·ª•ng nh·∫≠n di·ªán c·∫£m x√∫c khu√¥n m·∫∑t (HOG + DNN)")
st.write("T·∫£i ·∫£nh l√™n, h·ªá th·ªëng s·∫Ω ph√°t hi·ªán khu√¥n m·∫∑t v√† d·ª± ƒëo√°n c·∫£m x√∫c t·ª´ng ng∆∞·ªùi.")

uploaded_file = st.file_uploader("üì∏ Ch·ªçn ·∫£nh", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # ... (ph·∫ßn x·ª≠ l√Ω ·∫£nh v√† d·ª± ƒëo√°n gi·ªØ nguy√™n nh∆∞ code c≈© c·ªßa b·∫°n) ...

    # Gi·ªØ l·∫°i logic x·ª≠ l√Ω ·∫£nh c≈© c·ªßa b·∫°n
    img = Image.open(uploaded_file)
    img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)

    # === (1) Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·ªÉ ph√°t hi·ªán m·∫∑t t·ªët h∆°n ===
    img_cv = cv2.convertScaleAbs(img_cv, alpha=1.2, beta=15)
    img_cv = cv2.GaussianBlur(img_cv, (3, 3), 0)

    (h, w) = img_cv.shape[:2]
    blob = cv2.dnn.blobFromImage(cv2.resize(img_cv, (300, 300)), 1.0,
                                 (300, 300), (104.0, 177.0, 123.0))
    net.setInput(blob)
    detections = net.forward()

    count = 0
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        # === (2) Gi·∫£m ng∆∞·ª°ng confidence ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c m·∫∑t nghi√™ng / b·ªã che ===
        if confidence < 0.15:
            continue

        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
        (x1, y1, x2, y2) = box.astype("int")
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w - 1, x2), min(h - 1, y2)

        # ====== C·∫ÆT KHU√îN M·∫∂T ======
        face = img_cv[y1:y2, x1:x2]
        if face.size == 0:
            continue

        # === (3) L√†m m·ªãn v√πng khu√¥n m·∫∑t ƒë·ªÉ HOG ·ªïn ƒë·ªãnh ===
        face = cv2.resize(face, (96, 96))
        face = cv2.GaussianBlur(face, (3, 3), 0)

        gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
        face_resized = cv2.resize(gray, (48, 48), interpolation=cv2.INTER_AREA)

        # ====== TR√çCH XU·∫§T HOG ======
        features, _ = hog(
            face_resized,
            orientations=9,
            pixels_per_cell=(8, 8),
            cells_per_block=(2, 2),
            block_norm='L2-Hys',
            visualize=True
        )
        features = features.reshape(1, -1)

        # KI·ªÇM TRA SCALER V√Ä D·ª∞ ƒêO√ÅN
        if scaler is not None:
             if features.shape[1] != scaler.n_features_in_:
                st.warning(f"S·ªë ƒë·∫∑c tr∆∞ng HOG kh√¥ng kh·ªõp: {features.shape[1]} vs {scaler.n_features_in_}")
                continue
             features_scaled = scaler.transform(features)
        else:
             features_scaled = features # D√πng features g·ªëc n·∫øu kh√¥ng t√¨m th·∫•y scaler (ch·ªâ n√™n d√πng ƒë·ªÉ debug)
             st.warning("Ti·∫øp t·ª•c d·ª± ƒëo√°n m√† kh√¥ng d√πng Scaler.")

        pred = model.predict(features_scaled)[0]

        if isinstance(labels, list):
            try:
                label = labels[int(pred)]
            except:
                label = str(pred)
        else:
            label = str(pred)

        cv2.rectangle(img_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img_cv, label, (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

        count += 1

    if count == 0:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t n√†o r√µ r√†ng trong ·∫£nh.")
    else:
        st.image(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB),
                 caption="K·∫øt qu·∫£ nh·∫≠n di·ªán c·∫£m x√∫c",
                 use_container_width=True)